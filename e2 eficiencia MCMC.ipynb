{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\n",
    "\n",
    "**05/06/2020 - E2 S9**\n",
    "\n",
    "\n",
    "**Integrantes del grupo**:  \n",
    "- Guillermo Dinamarca\n",
    "- Pablo Araya Z.\n",
    "- Ignacio Zurita T."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "La estructura de esta evaluación consta de 5 preguntas. Tenga en cuenta que un problema de programación puede (por lo general) resolverse de múltiples maneras. Sin embargo, para optar al puntaje completo en cada pregunta, siga las indicaciones de los enunciados y utilice solo herramientas vistas en el curso. \n",
    "\n",
    "En lo que sigue de la evaluación, **no** estará permitido usar librerías ni módulos diferentes a los declarados en la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The line_profiler extension is already loaded. To reload it, use:\n  %reload_ext line_profiler\nThe cython extension is already loaded. To reload it, use:\n  %reload_ext cython\n"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "%load_ext line_profiler\n",
    "%load_ext cython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle as pk\n",
    "import os\n",
    "import warnings\n",
    "import math\n",
    "import glob\n",
    "\n",
    "from scipy import stats\n",
    "from functools import lru_cache\n",
    "from scipy import sparse \n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from multiprocessing import Process, cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es implementar **eficientemente** el algoritmo de regresión logística bayesiana, entrenado mediante un método de Markov Chain Montecarlo (MCMC), específicamente Metropolis-Hastings.\n",
    "\n",
    "Para trabajar en esta evaluación, construya un repositorio Git y resuelva las preguntas de este notebook utilizando tal repositorio. El formato de entrega es un archivo **.zip** con el repositorio correspondiente a este trabajo, no olvide incluir la carpeta `.git` asociada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminares\n",
    "\n",
    "Se trabajará en un problema de **clasificación binaria** sobre un conjunto de datos. Tal conjunto, describe  el comportamiento de clientes en un banco frente a una llamada telefónica, en la cual se les ofrece un depósito a plazo. \n",
    "\n",
    "La variable objetivo del conjunto de datos describe si el cliente se subscribió o no luego de la llamada. Si bien no es necesario entender el significado de cada variable para el correcto desarrollo del ejercicio, en `data/readme.md` encontrarán una descripción de estas.\n",
    "\n",
    "#### Carga de datos\n",
    "Compruebe que la siguiente celda coincide con este output:\n",
    "\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 11162 entries, 0 to 11161\n",
    "Data columns (total 17 columns):\n",
    " #   Column        Non-Null Count  Dtype   \n",
    "---  ------        --------------  -----   \n",
    " 0   age           11162 non-null  int8    \n",
    " 1   job           11162 non-null  category\n",
    " 2   marital       11162 non-null  category\n",
    " 3   education     11162 non-null  category\n",
    " 4   default       11162 non-null  bool    \n",
    " 5   balance       11162 non-null  int64   \n",
    " 6   housing       11162 non-null  bool    \n",
    " 7   loan          11162 non-null  bool    \n",
    " 8   contact       11162 non-null  category\n",
    " 9   month         11162 non-null  category\n",
    " 10  campaign      11162 non-null  int64   \n",
    " 11  pdays         11162 non-null  int64   \n",
    " 12  previous      11162 non-null  int64   \n",
    " 13  poutcome      11162 non-null  category\n",
    " 14  outcome       11162 non-null  bool    \n",
    " 15  day_of_week   11162 non-null  category\n",
    " 16  log_duration  11162 non-null  float64 \n",
    "dtypes: bool(4), category(7), float64(1), int64(4), int8(1)\n",
    "memory usage: 568.7 KB\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11162 entries, 0 to 11161\nData columns (total 17 columns):\n #   Column        Non-Null Count  Dtype   \n---  ------        --------------  -----   \n 0   age           11162 non-null  int8    \n 1   job           11162 non-null  category\n 2   marital       11162 non-null  category\n 3   education     11162 non-null  category\n 4   default       11162 non-null  bool    \n 5   balance       11162 non-null  int64   \n 6   housing       11162 non-null  bool    \n 7   loan          11162 non-null  bool    \n 8   contact       11162 non-null  category\n 9   month         11162 non-null  category\n 10  campaign      11162 non-null  int64   \n 11  pdays         11162 non-null  int64   \n 12  previous      11162 non-null  int64   \n 13  poutcome      11162 non-null  category\n 14  outcome       11162 non-null  bool    \n 15  day_of_week   11162 non-null  category\n 16  log_duration  11162 non-null  float64 \ndtypes: bool(4), category(7), float64(1), int64(4), int8(1)\nmemory usage: 568.7 KB\n"
    }
   ],
   "source": [
    "with open('data/trans_bank_marketing_codes-dtype.pk', 'rb') as file:\n",
    "    \n",
    "    dtypes_dict = pk.load(file)\n",
    "\n",
    "reg_df = pd.read_csv('data/trans_bank_marketing_codes.csv', dtype=dtypes_dict)\n",
    "reg_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento\n",
    "\n",
    "Los datos son cargados y preprocesados según las herramientas vistas en el curso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar variables explicativas de objetivo\n",
    "X = reg_df.loc[:, reg_df.columns[reg_df.columns != 'outcome']]\n",
    "y = reg_df['outcome']\n",
    "\n",
    "# separar conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# categorizar las columnas para ColumnTransformer\n",
    "\n",
    "int_cols = X_train.select_dtypes('int64').columns.tolist()\n",
    "float_cols = X_train.select_dtypes('float64').columns.tolist()\n",
    "bool_cols = X_train.select_dtypes('bool').columns.tolist()\n",
    "\n",
    "one_hot_cols = X_train.select_dtypes('category').columns.tolist() + \\\n",
    "    X_train.select_dtypes('int8').columns.tolist()\n",
    "\n",
    "# inicializar ColumnTransformer\n",
    "col_trans = ColumnTransformer([\n",
    "    ('continuous_std', StandardScaler(), float_cols),\n",
    "    ('minmax', MinMaxScaler(), int_cols),\n",
    "    ('passthrough_bool', 'passthrough', bool_cols),\n",
    "    ('one_hot', OneHotEncoder(drop='first'), one_hot_cols)\n",
    "])\n",
    "\n",
    "# asegurar todas las columnas del conjunto de datos son utilizadas\n",
    "assert X.columns.isin(int_cols + float_cols + bool_cols + one_hot_cols).all(), \\\n",
    "    'No todas las columnas son consideradas en ColumnTransformer'\n",
    "\n",
    "# obtener los arreglos que se utilizaran en el ejercicio\n",
    "X_mcmc = col_trans.fit_transform(X_train)\n",
    "X_mcmc = sparse.hstack((np.ones((X_mcmc.shape[0], 1)), X_mcmc))\n",
    "y_mcmc = y_train.astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística Bayesiana\n",
    "\n",
    "Dado un conjunto de observaciones para un problema de clasificación binario $\\mathcal{D}= \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{N} \\in \\mathbb{R}^{d} \\times \\{0,1\\}$ el modelo de regresión logística se determina por:\n",
    "\n",
    "$$\n",
    "p(y_i = 1 | \\mathbf{x}) = \\sigma(\\mathbf{w}^T\\mathbf{x})\n",
    "$$\n",
    "\n",
    "donde:\n",
    "$$\n",
    "\\sigma(\\mathbf{w}^T\\mathbf{x}) = \\frac{1}{1 + \\exp{(- \\mathbf{w}^T\\mathbf{x}})}\n",
    "$$\n",
    "\n",
    "Se asume la convención $\\mathbf{x}_i = (x_i, 1) \\forall i$, $x_i$ vector de características, esto permite codificar $\\mathbf{w} \\in \\mathbb{R}^{d}$. La verosimilitud asociada a este modelo viene dada por:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y} | \\mathbf{w})=\\prod_{n=1}^{N}  \\sigma(\\mathbf{w}^T\\mathbf{x}_n)^{y_n}\\left\\{1-\\sigma(\\mathbf{w}^T\\mathbf{x}_n)\\right\\}^{1-y_n}\n",
    "$$\n",
    "\n",
    "Si se escoge una probabilidad *prior* normal isotrópica $p(\\mathbf{w})= \\mathcal{N}\\left(\\mathbf{w} | \\mathrm{\\mu}_{w}, \\sigma_w^2 I \\right)$, el calculo de la distribución posterior $p(\\mathbf{w} | \\mathbf{y})$ se vuelve intratable. Esto pues, se hace necesario normalizar el producto de las probabilidades $p(\\mathbf{y} | \\mathbf{w})p(\\mathbf{w})$, para lo cual no se tiene una expresión analítica. Por tal motivo, la distribución posterior predictiva\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}_{*} | \\mathbf{w},\\mathbf{x}_{*}) = \\int \\sigma(\\mathbf{w}^T\\mathbf{x}_*) p(\\mathbf{w} | \\mathbf{y}) d\\mathbf{w}\n",
    "$$\n",
    "\n",
    "no puede ser calculada de manera explicita. Se busca por tanto, aproximar la probabilidad posterior $p(\\mathbf{w} | \\mathbf{y})$ y utilizar dicha aproximación para hacer predicciones por medio de $p(\\mathbf{y} | \\mathbf{w})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1\n",
    "\n",
    "Para comenzar, se definen los objetos necesarios para capturar el modelo de regresión logística bayesiana.\n",
    "\n",
    "1. Defina con `numpy` la función sigmoide y la log verosimilitud de la regresión logística. Compruebe que para el vector `w_inicial` obtiene aproximadamente `-3271`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-3270.7592662676516"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "class RegresionLogisticaMixin():\n",
    "    '''Clase Mixin para el calculo de la log verosimilitud de un modelo \n",
    "    de regresion logistica'''\n",
    "    \n",
    "    def sigmoide(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "        \n",
    "    # metodo protegido (por compatibilidad de version posterior)\n",
    "    def _log_verosimilitud(self, w, X, y):\n",
    "        var = X@w\n",
    "        sigmas = np.array([self.sigmoide(var[i]) for i in range(len(var))])\n",
    "        return np.sum( y@np.log(sigmas) + (1-y)@np.log(1-sigmas) )\n",
    "\n",
    "w_inicial = np.load('modelos/w_inicial.npy')\n",
    "RegresionLogisticaMixin()._log_verosimilitud(w_inicial, X_mcmc, y_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### MCMC\n",
    "\n",
    "Para lograr la aproximación de $p(\\mathbf{y} | \\mathbf{w})$ se utiliza un esquema de *Markov Chain Monte Carlo* (MCMC). Este se basa en la construcción de una cadena de Markov con distribución estacionaria \n",
    "$p(\\mathbf{w} | \\mathbf{y})$. Para construir esta cadena, se generan muestras de $\\mathbf{w}$ en el espacio de estados $\\mathbb{R}^d$ por medio de una distribución generadora de propuestas $q(\\mathbf{w})$. Luego se define una regla de transición, por medio del cual se evalúa si las muestras propuestas son aceptadas como representantes de $p(\\mathbf{w} | \\mathbf{y})$. \n",
    "\n",
    "El resultado del esquema MCMC es un conjunto de muestras provenientes de la distribución posterior deseada. Es conjunto de muestras se denota como **traza**. Para comprender la dinámica de selección de muestras consideremos el siguiente caso:\n",
    "\n",
    "Supongamos que se acepta la muestra $\\mathbf{w}_1$, luego se genera una nueva muestra (propuesta) $\\mathbf{w}_2$ por medio de $q(\\cdot| \\mathbf{w}_1)$. Para evaluar si esta nueva muestra es aceptada como miembro de la cadena,  se define el *coeficiente de aceptación* $\\alpha ( \\mathbf{w}_1 , \\mathbf{w}_2 ) = \\min \\left[ 1 , \\frac { p ( \\mathbf{w}_2 | \\mathbf{y})  q ( \\mathbf{w}_1 | \\mathbf{w}_2 ) } { p ( \\mathbf{w}_1 | \\mathbf{y}) q (\\mathbf{w}_2 | \\mathbf{w}_1 ) } \\right]$. No se conoce el valor de  $p ( \\mathbf{w} | \\mathbf{y})$ pero se sabe que\n",
    "\n",
    "$$\n",
    "p(\\mathbf{w} | \\mathbf{y}) \\propto p(\\mathbf{y} | \\mathbf{w})p(\\mathbf{w})\n",
    "$$\n",
    "\n",
    "Luego \n",
    "\n",
    "$$\n",
    "\\frac { p ( \\mathbf{w}_2 | \\mathbf{y})  q ( \\mathbf{w}_1 | \\mathbf{w}_2 ) } { p ( \\mathbf{w}_1 | \\mathbf{y}) q (\\mathbf{w}_2 | \\mathbf{w}_1 ) } \n",
    "=\n",
    "\\frac { p(\\mathbf{y} | \\mathbf{w}_2)q ( \\mathbf{w}_1 | \\mathbf{w}_2 ) p(\\mathbf{w}_2)}{ p(\\mathbf{y} | \\mathbf{w}_1) q (\\mathbf{w}_2 | \\mathbf{w}_1 )p(\\mathbf{w}_1) }\n",
    "$$\n",
    "\n",
    "Lo cual nos permite simular muestras de la posterior por medio de evaluaciones de la verosimilitud y prior del modelo. La variante de MCMC propuesta en este ejercicio de conoce como *Metropolis Hastings*. El algoritmo se describe a continuación:\n",
    "\n",
    "0. Como entrada del algoritmo se requiere $\\mathbf{w}_0$, la verosimilitud del modelo, la probabilidad prior para $\\mathbf{w}$ y una distribución generadora de propuestas $q(\\cdot)$. Como salida del algoritmo se tendrán `N` vectores `w_1`, ..., `w_N`.\n",
    "\n",
    "1. Para `i=1` hasta `N`:\n",
    "    1. Obtener una muestra `w_prop` de $q(\\cdot |\\mathbf{w}_{i-1})$.\n",
    "    2. Obtener una muestra de una variable aleatoria uniforme $U$.\n",
    "    3. Si $U < \\frac { p(\\mathbf{y} | \\mathbf{w}_{prop})q ( \\mathbf{w}_{i-1} | \\mathbf{w}_{prop} ) p(\\mathbf{w}_{prop})}{ p(\\mathbf{y} | \\mathbf{w}_{i-1}) q (\\mathbf{w}_{prop} | \\mathbf{w}_1 )p(\\mathbf{w}_{i-1}) }$ entonces $\\mathbf{w}_i =$ `w_prop`. En caso contrario $\\mathbf{w}_i = \\mathbf{w}_{i-1}$.\n",
    "\n",
    "Dado que la convergencia a $p(\\mathbf{w} | \\mathbf{y})$ se tiene en el infinito, las primeras muestras obtenidas por la cadena no son recomendables como representantes de la distribución posterior, eliminar cierta cantidad de muestras al inicio de la cadena se denomina *quemar la cadena*. Por otra parte, dado que las muestras obtenidas provienen de una cadena de Markov, estas son altamente dependientes entre si, por lo que se recomienda seleccionar muestras de la traza cada cierta cantidad de *saltos* o *leaps* para evitar dependencia entre las muestras obtenidas. Por último, si se posee un conjunto de muestras $\\mathbf{w}_1, ..., \\mathbf{w}_M$ provenientes de $p(\\mathbf{w} | \\mathbf{y})$, es posible aproximar la distribución posterior predictiva por medio de:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}_{*} | \\mathbf{w},\\mathbf{x}_{*}) = \\int \\sigma(\\mathbf{w}^T\\mathbf{x}_*) p(\\mathbf{w} | \\mathbf{y}) d\\mathbf{w} \\approx \\frac{1}{M} \\sum_{i = 1}^{M} \\sigma(\\mathbf{w}_i^T\\mathbf{x}_{*})\n",
    "$$\n",
    "\n",
    "\n",
    "A continuación se implementa dicho algoritmo para una distribución de propuestas normal isotrópica. Estudie con antención el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionLogisticaBayesianaMHV0(BaseEstimator, ClassifierMixin,\n",
    "                                      RegresionLogisticaMixin):\n",
    "    def __init__(self, w_inicial, media_priori, std_priori, std_proposal,\n",
    "                 n_muestras):\n",
    "\n",
    "        # parametros metropolis hastings\n",
    "        self.w_inicial = w_inicial\n",
    "        self.media_priori = media_priori\n",
    "        self.std_priori = std_priori\n",
    "        self.std_proposal = std_proposal\n",
    "        self.n_muestras = n_muestras\n",
    "\n",
    "        # atributos inferidos\n",
    "        self.dim_parametros = self.w_inicial.shape[0]\n",
    "        self.traza = np.zeros((\n",
    "            self.n_muestras + 1,\n",
    "            self.dim_parametros,\n",
    "        ))\n",
    "        self.traza[0] = self.w_inicial\n",
    "\n",
    "    def get_metropolis_hastings_candidatos(self):\n",
    "        '''    \n",
    "        Obtiene las muestras de una normal multivariada isotropica para \n",
    "        utilizarlos como candidatos de la cadena de Markov.\n",
    "        '''\n",
    "        distribucion_candidatos = stats.multivariate_normal(\n",
    "            mean=np.zeros(self.dim_parametros),\n",
    "            cov=(self.std_proposal**2) * np.eye(self.dim_parametros))\n",
    "\n",
    "        return distribucion_candidatos.rvs(size=self.n_muestras)\n",
    "\n",
    "    def get_metropolis_hastings_uniformes(self):\n",
    "        '''    \n",
    "        Obtiene las muestras de una normal multivariada isotropica para \n",
    "        utilizarlos como candidatos de la cadena de Markov.\n",
    "        '''\n",
    "\n",
    "        return np.random.uniform(size=(self.n_muestras, ))\n",
    "\n",
    "    def get_priori(self):\n",
    "        '''\n",
    "        Prior Gaussiana con media mu_w y covarianza esferica sigma_w**2 I\n",
    "        '''\n",
    "        return stats.multivariate_normal(mean=self.media_priori,\n",
    "                                         cov=(self.std_priori**2) *\n",
    "                                         np.eye(self.dim_parametros))\n",
    "\n",
    "    def metropolis_hastings(self, X, y, semilla):\n",
    "        '''\n",
    "        Muestrea el espacio de los parametros mediante Metropolis-Hastings\n",
    "        '''\n",
    "\n",
    "        # asegura replicabilidad\n",
    "        np.random.seed(semilla)\n",
    "\n",
    "        # obtiene distribucion a priori y candidatos\n",
    "        distribucion_priori = self.get_priori()\n",
    "        W_candidatos = self.get_metropolis_hastings_candidatos()\n",
    "        U_aceptacion = self.get_metropolis_hastings_uniformes()\n",
    "\n",
    "        # contador de candidatos aceptados\n",
    "        aceptados = 0\n",
    "\n",
    "        for i, w_candidato in enumerate(W_candidatos):\n",
    "\n",
    "            # localiza distribucion candidatos en w_actual\n",
    "            w_actual = self.traza[i]\n",
    "            w_candidato += w_actual\n",
    "\n",
    "            # calcula prior\n",
    "            delta_prior = distribucion_priori.logpdf(w_candidato) - \\\n",
    "                distribucion_priori.logpdf(w_actual)\n",
    "\n",
    "            # calcula verosimilitud\n",
    "            delta_verosimilitud = self._log_verosimilitud(w_candidato, X, y) - \\\n",
    "                self._log_verosimilitud(w_actual, X, y)\n",
    "\n",
    "            # probabilidad de aceptacion\n",
    "            p_aceptacion = math.exp(delta_verosimilitud + delta_prior)\n",
    "\n",
    "            if U_aceptacion[i] < p_aceptacion:\n",
    "\n",
    "                # actualiza valor actual y contador de aceptados\n",
    "                w_actual = w_candidato\n",
    "                aceptados += 1\n",
    "\n",
    "            self.traza[i + 1] = w_actual\n",
    "\n",
    "        # almacena la proporcion de candidatos aceptados\n",
    "        self.proporcion_aceptacion = aceptados / self.n_muestras\n",
    "\n",
    "    def fit(self, X, y, n_muestras_quemadas=0, leap=10, semilla=6202):\n",
    "\n",
    "        # obtener traza mediante Metropolis Hastings\n",
    "        self.metropolis_hastings(X, y, semilla)\n",
    "\n",
    "        # obtener muestras posterior\n",
    "        self.w_post = self.traza[n_muestras_quemadas::leap, ]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Aproximacion de la posterior predictiva\n",
    "        return np.mean(self.sigmoide(X @ self.w_post.T), axis=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # maneja aproximacion de 0.5 a 1 (por comportamiento \"round half\n",
    "        # to even\")\n",
    "        return np.round(1 + self.predict_proba(X)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueban los resultados de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros MCMC\n",
    "_, std_inicial = stats.norm.fit(w_inicial, floc=0)\n",
    "media_prior = np.zeros(w_inicial.shape)\n",
    "std_poposal = 1e-2\n",
    "n_samples = int(1e3) \n",
    "\n",
    "# Entrenamiento\n",
    "rlb_v0 = RegresionLogisticaBayesianaMHV0(w_inicial,media_prior,std_inicial,std_poposal,n_samples)\n",
    "rlb_v0.fit(X_mcmc, y_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy en conjunto de entrnamiento:  0.8329948632182534\nProporcion de muestras aceptadas MCMC: 0.61\n"
    }
   ],
   "source": [
    "# Resultados\n",
    "ac_rlb = accuracy_score(rlb_v0.predict(X_mcmc), y_mcmc)\n",
    "print('Accuracy en conjunto de entrnamiento: ', ac_rlb)\n",
    "print('Proporcion de muestras aceptadas MCMC:', rlb_v0.proporcion_aceptacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reporte el tiempo de ejecución de cada línea del método `metropolis_hastings` en un archivo de texto llamado `RegresionLogisticaBayesianaMHV0.txt` en la carpeta `reportes`. Compruebe que  más de un 90% del tiempo se utiliza en la función `log_verosimilitud`. En lo que queda del ejercicio nos dedicaremos a optimizar este método. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n*** Profile printout saved to text file 'reportes/RegresionLogisticaBayesianaMHV0.txt'. \n"
    },
    {
     "output_type": "stream",
     "text": "Timer unit: 1e-07 s\n\nTotal time: 107.196 s\nFile: <ipython-input-12-d1d7f5981710>\nFunction: metropolis_hastings at line 48\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n    48                                               def metropolis_hastings(self, X, y, semilla):\n    49                                                   '''\n    50                                                   Muestrea el espacio de los parametros mediante Metropolis-Hastings\n    51                                                   '''\n    52                                           \n    53                                                   # asegura replicabilidad\n    54         1        301.0    301.0      0.0          np.random.seed(semilla)\n    55                                           \n    56                                                   # obtiene distribucion a priori y candidatos\n    57         1      57866.0  57866.0      0.0          distribucion_priori = self.get_priori()\n    58         1      95889.0  95889.0      0.0          W_candidatos = self.get_metropolis_hastings_candidatos()\n    59         1       1713.0   1713.0      0.0          U_aceptacion = self.get_metropolis_hastings_uniformes()\n    60                                           \n    61                                                   # contador de candidatos aceptados\n    62         1         13.0     13.0      0.0          aceptados = 0\n    63                                           \n    64      1001      24388.0     24.4      0.0          for i, w_candidato in enumerate(W_candidatos):\n    65                                           \n    66                                                       # localiza distribucion candidatos en w_actual\n    67      1000      17741.0     17.7      0.0              w_actual = self.traza[i]\n    68      1000      96871.0     96.9      0.0              w_candidato += w_actual\n    69                                           \n    70                                                       # calcula prior\n    71      1000    1284827.0   1284.8      0.1              delta_prior = distribucion_priori.logpdf(w_candidato) - \\\n    72      1000     748101.0    748.1      0.1                  distribucion_priori.logpdf(w_actual)\n    73                                           \n    74                                                       # calcula verosimilitud\n    75      1000  533727751.0 533727.8     49.8              delta_verosimilitud = self._log_verosimilitud(w_candidato, X, y) - \\\n    76      1000  535697878.0 535697.9     50.0                  self._log_verosimilitud(w_actual, X, y)\n    77                                           \n    78                                                       # probabilidad de aceptacion\n    79      1000      66254.0     66.3      0.0              p_aceptacion = math.exp(delta_verosimilitud + delta_prior)\n    80                                           \n    81      1000      60300.0     60.3      0.0              if U_aceptacion[i] < p_aceptacion:\n    82                                           \n    83                                                           # actualiza valor actual y contador de aceptados\n    84       610      12243.0     20.1      0.0                  w_actual = w_candidato\n    85       610       8318.0     13.6      0.0                  aceptados += 1\n    86                                           \n    87      1000      57082.0     57.1      0.0              self.traza[i + 1] = w_actual\n    88                                           \n    89                                                   # almacena la proporcion de candidatos aceptados\n    90         1         13.0     13.0      0.0          self.proporcion_aceptacion = aceptados / self.n_muestras"
    }
   ],
   "source": [
    "%lprun -T reportes/RegresionLogisticaBayesianaMHV0.txt -f rlb_v0.metropolis_hastings rlb_v0.metropolis_hastings(X_mcmc,y_mcmc,semilla=6202) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3\n",
    "**Optimice el algoritmo**: \n",
    "\n",
    "1. Haga anulación (*overriding*) del método `metropolis_hastings` para evitar que para un mismo input se compute más de una vez la log verosimilitud y la log probabilidad *a priori*. \n",
    "2. Discuta en la celda subsiguiente por qué el uso de `@lru_cache` no es ideal.\n",
    "3. Reporte el tiempo de ejecución de cada línea del método `metropolis_hastings` en un archivo de texto llamado `RegresionLogisticaBayesianaMHV1.txt` en la carpeta `reportes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construya RegresionLogisticaBayesianaMHV1 aqui\n",
    "class RegresionLogisticaBayesianaMHV1(RegresionLogisticaBayesianaMHV0):\n",
    "     def metropolis_hastings(self, X, y, semilla):\n",
    "        '''\n",
    "        Muestrea el espacio de los parametros mediante Metropolis-Hastings\n",
    "        '''\n",
    "\n",
    "        # asegura replicabilidad\n",
    "        np.random.seed(semilla)\n",
    "\n",
    "        # obtiene distribucion a priori y candidatos\n",
    "        distribucion_priori = self.get_priori()\n",
    "        W_candidatos = self.get_metropolis_hastings_candidatos()\n",
    "        U_aceptacion = self.get_metropolis_hastings_uniformes()\n",
    "\n",
    "        # contador de candidatos aceptados\n",
    "        aceptados = 0\n",
    "\n",
    "        lver_actual = self._log_verosimilitud(self.traza[0],X,y)\n",
    "        for i, w_candidato in enumerate(W_candidatos):\n",
    "\n",
    "            # localiza distribucion candidatos en w_actual\n",
    "            w_actual = self.traza[i]\n",
    "            w_candidato += w_actual\n",
    "\n",
    "            # calcula prior\n",
    "            delta_prior = distribucion_priori.logpdf(w_candidato) - \\\n",
    "                distribucion_priori.logpdf(w_actual)\n",
    "            \n",
    "            ''' Seccion cambiada para optimizar el proceso'''\n",
    "            # calcula verosimilitud\n",
    "            ''' Generamos el candidato'''\n",
    "            lver_candidato = self._log_verosimilitud(w_candidato,X,y)\n",
    "            delta_verosimilitud = lver_candidato - lver_actual\n",
    "\n",
    "            # probabilidad de aceptacion\n",
    "            p_aceptacion = math.exp(delta_verosimilitud + delta_prior)\n",
    "\n",
    "            if U_aceptacion[i] < p_aceptacion:\n",
    "\n",
    "                # actualiza valor actual y contador de aceptados\n",
    "                w_actual = w_candidato\n",
    "                aceptados += 1\n",
    "                ''' Se actualiza el valor de la log verosimilitud del candidato'''\n",
    "                lver_actual = lver_candidato\n",
    "\n",
    "            self.traza[i+1] = w_actual\n",
    "\n",
    "        # almacena la proporcion de candidatos aceptados\n",
    "        self.proporcion_aceptacion = aceptados / self.n_muestras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escriba su discusión aquí.** (Extensión máxima 400 caracteres)\n",
    "\n",
    "\n",
    "\n",
    "Para utilizar lru-cache es necesario que los objetos que se agreguen sean inmutables lo cual no ocurre en este caso debido a que lo que se pretende agregar son arrays de numpy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "38.4 s ± 2.04 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "rlb_v1 = RegresionLogisticaBayesianaMHV1(w_inicial,media_prior,std_inicial,std_poposal,n_samples)\n",
    "\n",
    "%timeit rlb_v1.fit(X_mcmc, y_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n*** Profile printout saved to text file 'reportes/RegresionLogisticaBayesianaMHV1.txt'. \n"
    },
    {
     "output_type": "stream",
     "text": "Timer unit: 1e-07 s\n\nTotal time: 46.4836 s\nFile: <ipython-input-17-3d0d185e807a>\nFunction: metropolis_hastings at line 3\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     3                                                def metropolis_hastings(self, X, y, semilla):\n     4                                                   '''\n     5                                                   Muestrea el espacio de los parametros mediante Metropolis-Hastings\n     6                                                   '''\n     7                                           \n     8                                                   # asegura replicabilidad\n     9         1        249.0    249.0      0.0          np.random.seed(semilla)\n    10                                           \n    11                                                   # obtiene distribucion a priori y candidatos\n    12         1      56588.0  56588.0      0.0          distribucion_priori = self.get_priori()\n    13         1      83578.0  83578.0      0.0          W_candidatos = self.get_metropolis_hastings_candidatos()\n    14         1        647.0    647.0      0.0          U_aceptacion = self.get_metropolis_hastings_uniformes()\n    15                                           \n    16                                                   # contador de candidatos aceptados\n    17         1         18.0     18.0      0.0          aceptados = 0\n    18                                           \n    19         1     613799.0 613799.0      0.1          lver_actual = self._log_verosimilitud(self.traza[0],X,y)\n    20      1001      24414.0     24.4      0.0          for i, w_candidato in enumerate(W_candidatos):\n    21                                           \n    22                                                       # localiza distribucion candidatos en w_actual\n    23      1000      18260.0     18.3      0.0              w_actual = self.traza[i]\n    24      1000      94158.0     94.2      0.0              w_candidato += w_actual\n    25                                           \n    26                                                       # calcula prior\n    27      1000    1112115.0   1112.1      0.2              delta_prior = distribucion_priori.logpdf(w_candidato) - \\\n    28      1000     737577.0    737.6      0.2                  distribucion_priori.logpdf(w_actual)\n    29                                                       \n    30                                                       ''' Seccion cambiada para optimizar el proceso'''\n    31                                                       # calcula verosimilitud\n    32                                                       ''' Generamos el candidato'''\n    33      1000  461865232.0 461865.2     99.4              lver_candidato = self._log_verosimilitud(w_candidato,X,y)\n    34      1000      41300.0     41.3      0.0              delta_verosimilitud = lver_candidato - lver_actual\n    35                                           \n    36                                                       # probabilidad de aceptacion\n    37      1000      47630.0     47.6      0.0              p_aceptacion = math.exp(delta_verosimilitud + delta_prior)\n    38                                           \n    39      1000      54398.0     54.4      0.0              if U_aceptacion[i] < p_aceptacion:\n    40                                           \n    41                                                           # actualiza valor actual y contador de aceptados\n    42       610      13526.0     22.2      0.0                  w_actual = w_candidato\n    43       610       8276.0     13.6      0.0                  aceptados += 1\n    44                                                           ''' Se actualiza el valor de la log verosimilitud del candidato'''\n    45       610       5959.0      9.8      0.0                  lver_actual = lver_candidato\n    46                                           \n    47      1000      58364.0     58.4      0.0              self.traza[i+1] = w_actual\n    48                                           \n    49                                                   # almacena la proporcion de candidatos aceptados\n    50         1         23.0     23.0      0.0          self.proporcion_aceptacion = aceptados / self.n_muestras"
    }
   ],
   "source": [
    "%lprun -T reportes/RegresionLogisticaBayesianaMHV1.txt -f rlb_v1.metropolis_hastings rlb_v1.metropolis_hastings(X_mcmc,y_mcmc,semilla=6202) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4\n",
    "**Procesos distribuidos**. \n",
    "\n",
    "1. Implemente la clase `ProcesoRegresionLogisticaBayesianaMHV1`, que herede de `Process` y `RegresionLogisticaBayesianaMHV1`, cuyo objetivo es guardar en el disco la traza obtenida en el proceso de entrenamiento.\n",
    "2. Obtenga tantas trazas de como nucleos tenga el procesador de su computador. Dichas trazas deben ser guardadas en la carpeta `trazas`, con el nombre del archivo según el formato `s_DDDD.npy` donde `DDDD` es un entero de 4 dígitos que representa la semilla utilizada para la obtención de dicha traza. *Hint*: puede obtener el número de núcleos de su procesador mediante la función `cpu_count()` de la librería `multiprocessing`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construya ProcesoRegresionLogisticaBayesianaMHV1 aqui\n",
    "class ProcesoRegresionLogisticaBayesianaMHV1(Process, RegresionLogisticaBayesianaMHV1):\n",
    "    \n",
    "    def __init__(self, w_inicial, media_priori, std_priori, std_proposal,\n",
    "                 n_muestras, X, y, n_muestras_quemadas=0, leap=10, semilla=6202):\n",
    "        super().__init__()\n",
    "\n",
    "        # parametros metropolis hastings\n",
    "        self.w_inicial = w_inicial\n",
    "        self.media_priori = media_priori\n",
    "        self.std_priori = std_priori\n",
    "        self.std_proposal = std_proposal\n",
    "        self.n_muestras = n_muestras\n",
    "\n",
    "        # atributos inferidos\n",
    "        self.dim_parametros = self.w_inicial.shape[0]\n",
    "        self.traza = np.zeros((\n",
    "            self.n_muestras + 1,\n",
    "            self.dim_parametros,\n",
    "        ))\n",
    "        self.traza[0] = self.w_inicial\n",
    "        \n",
    "        #Inputs\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_muestras_quemadas = n_muestras_quemadas\n",
    "        self.leap = leap\n",
    "        self.semilla = semilla\n",
    "        \n",
    "    def fit(self):\n",
    "\n",
    "        # obtener traza mediante Metropolis Hastings\n",
    "        self.metropolis_hastings(self.X, self.y, self.semilla)\n",
    "\n",
    "        # obtener muestras posterior\n",
    "        self.w_post = self.traza[self.n_muestras_quemadas::self.leap, ]\n",
    "        \n",
    "    def run(self):\n",
    "        self.fit()\n",
    "        np.save('trazas/s_'+str(self.semilla)+ '.npy', self.traza)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "semillas = np.random.randint(1000,9999,n_cores)\n",
    "proc = [ProcesoRegresionLogisticaBayesianaMHV1(w_inicial,\n",
    "                                               media_prior,\n",
    "                                               std_inicial,\n",
    "                                               std_poposal,\n",
    "                                               n_samples, \n",
    "                                               X_mcmc, \n",
    "                                               y_mcmc, \n",
    "                                               semilla = sem) for sem in semillas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a6ec3b146297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tiempo de ejecución: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-a6ec3b146297>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tiempo de ejecución: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "[*map(lambda p: p.start(), proc)]\n",
    "[p.join() for p in proc]\n",
    "print('Tiempo de ejecución: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo aproximado para una ejecución del método *fit()*, es de $21.2 [s]$, mientras que, utlizando multiprocessing, en una máquina con 8 núcleos, el tiempo total de ejecución de 8 veces el método *fit()*, es de $83.9 [s]$, lo que da un promedio de $10.49 [s]$ por ejecución, es decir, se redujo alrededor de un $50\\%$ el tiempo de procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log verosimilitud en Cython\n",
    "Para finalizar implementaremos una versión en Cython para la log verosimilitud. En la siguiente celda adaptaremos los tipos de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cython = X_mcmc.toarray().astype('float32')\n",
    "y_cython = y_mcmc.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5\n",
    "**Versión cython de la Log veorsimilitud**\n",
    "\n",
    "1. Implemente la clase de cython `LogVerosimilitud`. Esta debe:\n",
    "    - Inicializarse con los argumentos `X` e `y` de tamaño conocido, es decir puede asumir que `X.shape = (8371, 56)` y que `y.shape = (8371,)`. *Hint*: Puede ser útil usar variables globales por medio del comando `DEF`.\n",
    "    - Poseer el método `get()` que opera sobre un arreglo de NumPy `w` y retorna su log verosimilitud. *Hint*: puede ser de utilidad el decorador `@cython.cdivision`.\n",
    "    - Transformar los arreglos de numpy (`X`, `y` y `w`) en arreglos de C.\n",
    "    - Minimizar la interacción con python, para acelerar el cómputo lo más posible. Para verificar esto utilice el `magic` de celda `%%cython -a`.\n",
    "\n",
    "*Hint*: utilice las funciones `exp` y `log` de `libc.math` de `cython`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "UsageError: %%cython is a cell magic, but the cell body is empty.\n"
    }
   ],
   "source": [
    "%%cython -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compruebe que su implementación retorna la verosimilitud ya conocida para `w_inicial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libc.math cimport exp \n",
    "from libc.math cimport log \n",
    "\n",
    "\n",
    "cdef class LogVeroimilitud(self, X,y):\n",
    "    cdef np.ndarray Xshape = X.shape\n",
    "    cdef np.ndarray yshape = y.shape\n",
    "\n",
    "    def __cinit__(self,X,y):\n",
    "    def get(self, np.ndarray w):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compruebe que dados los mismos inputs `X_cython` y `y_cython`, la versión de Cython es más eficaz, pero que sin embargo, la más rápida es la versión de `numpy` en los inputs de `X_mcmc` e `y_mcmc`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus (sin puntaje)\n",
    "\n",
    "El valor de `w_inicial` utilizado en este ejercicio fue obtenido por medio de máxima verosimilitud. A continuación compararemos los resultados de scikit-learn, utilizando el parámetro de máxima verosimilitud con el enfoque bayesiano implementado a lo largo de esta evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X, w):\n",
    "    '''\n",
    "    Clasificador Logistico\n",
    "    '''\n",
    "    mixin = RegresionLogisticaMixin()\n",
    "    probs = mixin.sigmoide(X @ w)\n",
    "    \n",
    "    return np.round(1 + probs) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparar los datos del conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mcmc_test = col_trans.fit_transform(X_test)\n",
    "X_mcmc_test = sparse.hstack((np.ones((X_mcmc_test.shape[0], 1)), X_mcmc_test))\n",
    "y_mcmc_test = y_test.astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicaliza el modelo bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, std_inicial = stats.norm.fit(w_inicial, floc=0)\n",
    "media_prior = np.zeros(w_inicial.shape)\n",
    "std_poposal = 1e-2\n",
    "n_samples = int(1e3)\n",
    "\n",
    "rlb_v1 = RegresionLogisticaBayesianaMHV1(w_inicial, media_prior, std_inicial,\n",
    "                                         std_poposal, n_samples)\n",
    "rlb_v1.fit(X_mcmc, y_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación en métricas de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn = log_reg(X_mcmc_test, w_inicial)\n",
    "y_pred_rlb = rlb_v1.predict(X_mcmc_test)\n",
    "\n",
    "ac_skl = accuracy_score(y_pred_sklearn, y_test)\n",
    "f1_skl = f1_score(y_pred_sklearn, y_test)\n",
    "ac_rlb = accuracy_score(y_pred_rlb, y_test)\n",
    "f1_rlb = f1_score(y_pred_rlb, y_test)\n",
    "print('Accuracy sk-learn: ', ac_skl)\n",
    "print('F1 score sk-learn: ', f1_skl)\n",
    "print('Accuracy RLB: ', ac_rlb)\n",
    "print('F1 score RLB: ', f1_rlb)\n",
    "print(f'Ac RLB >= MLE: {ac_rlb >= ac_skl}    F1 RLB >= MLE: {f1_rlb >= f1_skl}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar la posterior cargamos las trazas obtenidas durante el ejercicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_files = sorted(glob.glob('trazas/*.npy'))\n",
    "traza_concat = None\n",
    "\n",
    "for filename in np_files:\n",
    "    \n",
    "    traza = np.load(filename)\n",
    "    \n",
    "    if traza_concat is None:\n",
    "        \n",
    "        traza_concat = traza\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        traza_concat = np.concatenate((traza_concat, traza), axis=0)\n",
    "        \n",
    "traza_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la traza como la distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_fig = 'fig'\n",
    "archivo_figura = f'{dir_fig}/prop-{std_poposal:.0e}_nsamples-{n_samples:.0e}.png'\n",
    "sobrescribe = False\n",
    "\n",
    "xx = np.arange(traza_concat.shape[0])\n",
    "w_esperado = traza_concat.mean(0)\n",
    "\n",
    "nrows, ncols = traza_concat.shape[1], 2\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(5 * ncols, 3 * nrows), \n",
    "                         gridspec_kw={'hspace':.3})\n",
    "for i in range(nrows):\n",
    "    \n",
    "    # histograma posterior\n",
    "    ax_ = axes[i, 0]\n",
    "    ax_.set_title('Posterior w_' + str(i))\n",
    "    \n",
    "    # evita FutureWarnings en distplot\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        sns.distplot(traza_concat[:, i], ax=ax_)\n",
    "        \n",
    "    ax_.set_ylabel('frecuencia')\n",
    "    ax_.axvline(x=w_inicial[i], label='MLE', ls= '-.', c = 'r')\n",
    "    ax_.axvline(x=w_esperado[i], label = 'Esperado',ls= '--', c='black')\n",
    "    ax_.legend()\n",
    "    \n",
    "    # traza\n",
    "    ax_ = axes[i, 1]\n",
    "    ax_.scatter(x=xx, y = traza_concat[:, i], alpha=.6, s=.1)\n",
    "    ax_.set_ylabel('w_' + str(i))\n",
    "    ax_.set_title('Traza w_' + str(i))\n",
    "    \n",
    "axes[i, 0].set_xlabel('w_' + str(i));\n",
    "axes[i, 1].set_xlabel('Iteraciones'); \n",
    "if (not os.path.isfile(archivo_figura)) or sobrescribe:\n",
    "    fig.savefig(archivo_figura, bbxox_inches='tight')\n",
    "else:\n",
    "    print(f'Archivo existente,  y `sobrescribe` = {sobrescribe}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit (conda)",
   "language": "python",
   "name": "python36564bitcondac5f92f5d3def4e2098f14bdb67fe3049"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "nbTranslate": {
   "displayLangs": [
    "es",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}